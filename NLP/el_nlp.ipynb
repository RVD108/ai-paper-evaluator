{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import re\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "SavedModel file does not exist at: C:\\Users\\adity\\AppData\\Local\\Temp\\tfhub_modules\\4e9cb77ce3b4a217fd7ebc0fc6bbaa659a8cca42\\{saved_model.pbtxt|saved_model.pb}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[42], line 16\u001b[0m\n\u001b[0;32m     14\u001b[0m prepro_url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://www.kaggle.com/models/tensorflow/bert/TensorFlow2/en-uncased-preprocess/3\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     15\u001b[0m enc_url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://www.kaggle.com/models/tensorflow/bert/TensorFlow2/en-uncased-l-12-h-768-a-12/4\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 16\u001b[0m bert_prep_model \u001b[38;5;241m=\u001b[39m \u001b[43mhub\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mKerasLayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprepro_url\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m test_text \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhello there\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgeneral kenobi\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     18\u001b[0m prepro_txt \u001b[38;5;241m=\u001b[39m bert_prep_model(test_text)\n",
      "File \u001b[1;32mc:\\Users\\adity\\anaconda3\\envs\\myenv\\lib\\site-packages\\tensorflow_hub\\keras_layer.py:146\u001b[0m, in \u001b[0;36mKerasLayer.__init__\u001b[1;34m(self, handle, trainable, arguments, _sentinel, tags, signature, signature_outputs_as_dict, output_key, output_shape, **kwargs)\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_shape:\n\u001b[0;32m    141\u001b[0m   \u001b[38;5;66;03m# Autograph chokes on _convert_nest_to_shapes(), so we call it here\u001b[39;00m\n\u001b[0;32m    142\u001b[0m   \u001b[38;5;66;03m# and not from within call().\u001b[39;00m\n\u001b[0;32m    143\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_shape \u001b[38;5;241m=\u001b[39m data_structures\u001b[38;5;241m.\u001b[39mNoDependency(\n\u001b[0;32m    144\u001b[0m       _convert_nest_to_shapes(output_shape))\n\u001b[1;32m--> 146\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_func \u001b[38;5;241m=\u001b[39m \u001b[43mload_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_training_argument \u001b[38;5;241m=\u001b[39m func_has_training_argument(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_func)\n\u001b[0;32m    148\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_hub_module_v1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_func, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_is_hub_module_v1\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\adity\\anaconda3\\envs\\myenv\\lib\\site-packages\\tensorflow_hub\\keras_layer.py:398\u001b[0m, in \u001b[0;36mload_module\u001b[1;34m(handle, tags)\u001b[0m\n\u001b[0;32m    396\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m handle\n\u001b[0;32m    397\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 398\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodule_v2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtags\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\adity\\anaconda3\\envs\\myenv\\lib\\site-packages\\tensorflow_hub\\module_v2.py:102\u001b[0m, in \u001b[0;36mload\u001b[1;34m(handle, tags)\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tags \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m is_hub_module_v1:\n\u001b[0;32m    101\u001b[0m     tags \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m--> 102\u001b[0m obj \u001b[38;5;241m=\u001b[39m \u001b[43mtf_v1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msaved_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_v2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtags\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    103\u001b[0m obj\u001b[38;5;241m.\u001b[39m_is_hub_module_v1 \u001b[38;5;241m=\u001b[39m is_hub_module_v1  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    104\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj\n",
      "File \u001b[1;32mc:\\Users\\adity\\anaconda3\\envs\\myenv\\lib\\site-packages\\tensorflow\\python\\saved_model\\load.py:800\u001b[0m, in \u001b[0;36mload\u001b[1;34m(export_dir, tags, options)\u001b[0m\n\u001b[0;32m    798\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(export_dir, os\u001b[38;5;241m.\u001b[39mPathLike):\n\u001b[0;32m    799\u001b[0m   export_dir \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mfspath(export_dir)\n\u001b[1;32m--> 800\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mload_partial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexport_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mroot\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    801\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\adity\\anaconda3\\envs\\myenv\\lib\\site-packages\\tensorflow\\python\\saved_model\\load.py:905\u001b[0m, in \u001b[0;36mload_partial\u001b[1;34m(export_dir, filters, tags, options)\u001b[0m\n\u001b[0;32m    900\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tags \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tags, \u001b[38;5;28mset\u001b[39m):\n\u001b[0;32m    901\u001b[0m   \u001b[38;5;66;03m# Supports e.g. tags=SERVING and tags=[SERVING]. Sets aren't considered\u001b[39;00m\n\u001b[0;32m    902\u001b[0m   \u001b[38;5;66;03m# sequences for nest.flatten, so we put those through as-is.\u001b[39;00m\n\u001b[0;32m    903\u001b[0m   tags \u001b[38;5;241m=\u001b[39m nest\u001b[38;5;241m.\u001b[39mflatten(tags)\n\u001b[0;32m    904\u001b[0m saved_model_proto, debug_info \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m--> 905\u001b[0m     \u001b[43mloader_impl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse_saved_model_with_debug_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexport_dir\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    907\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mlen\u001b[39m(saved_model_proto\u001b[38;5;241m.\u001b[39mmeta_graphs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    908\u001b[0m     saved_model_proto\u001b[38;5;241m.\u001b[39mmeta_graphs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mHasField(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobject_graph_def\u001b[39m\u001b[38;5;124m\"\u001b[39m)):\n\u001b[0;32m    909\u001b[0m   metrics\u001b[38;5;241m.\u001b[39mIncrementReadApi(_LOAD_V2_LABEL)\n",
      "File \u001b[1;32mc:\\Users\\adity\\anaconda3\\envs\\myenv\\lib\\site-packages\\tensorflow\\python\\saved_model\\loader_impl.py:57\u001b[0m, in \u001b[0;36mparse_saved_model_with_debug_info\u001b[1;34m(export_dir)\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparse_saved_model_with_debug_info\u001b[39m(export_dir):\n\u001b[0;32m     45\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Reads the savedmodel as well as the graph debug info.\u001b[39;00m\n\u001b[0;32m     46\u001b[0m \n\u001b[0;32m     47\u001b[0m \u001b[38;5;124;03m  Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;124;03m    parsed. Missing graph debug info file is fine.\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m---> 57\u001b[0m   saved_model \u001b[38;5;241m=\u001b[39m \u001b[43mparse_saved_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexport_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     59\u001b[0m   debug_info_path \u001b[38;5;241m=\u001b[39m file_io\u001b[38;5;241m.\u001b[39mjoin(\n\u001b[0;32m     60\u001b[0m       saved_model_utils\u001b[38;5;241m.\u001b[39mget_debug_dir(export_dir),\n\u001b[0;32m     61\u001b[0m       constants\u001b[38;5;241m.\u001b[39mDEBUG_INFO_FILENAME_PB)\n\u001b[0;32m     62\u001b[0m   debug_info \u001b[38;5;241m=\u001b[39m graph_debug_info_pb2\u001b[38;5;241m.\u001b[39mGraphDebugInfo()\n",
      "File \u001b[1;32mc:\\Users\\adity\\anaconda3\\envs\\myenv\\lib\\site-packages\\tensorflow\\python\\saved_model\\loader_impl.py:115\u001b[0m, in \u001b[0;36mparse_saved_model\u001b[1;34m(export_dir)\u001b[0m\n\u001b[0;32m    113\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot parse file \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_to_pbtxt\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 115\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(\n\u001b[0;32m    116\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSavedModel file does not exist at: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexport_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mos\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    117\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m{{\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mconstants\u001b[38;5;241m.\u001b[39mSAVED_MODEL_FILENAME_PBTXT\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m|\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    118\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconstants\u001b[38;5;241m.\u001b[39mSAVED_MODEL_FILENAME_PB\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m}}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mOSError\u001b[0m: SavedModel file does not exist at: C:\\Users\\adity\\AppData\\Local\\Temp\\tfhub_modules\\4e9cb77ce3b4a217fd7ebc0fc6bbaa659a8cca42\\{saved_model.pbtxt|saved_model.pb}"
     ]
    }
   ],
   "source": [
    "# text_input = tf.keras.layers.Input(shape=(), dtype=tf.string)\n",
    "# preprocessor = hub.KerasLayer(\n",
    "#     \"https://kaggle.com/models/tensorflow/bert/TensorFlow2/en-uncased-preprocess/3\")\n",
    "# encoder_inputs = preprocessor(text_input)\n",
    "# encoder = hub.KerasLayer(\n",
    "#     \"https://www.kaggle.com/models/tensorflow/bert/TensorFlow2/en-uncased-l-12-h-768-a-12/4\",\n",
    "#     trainable=True)\n",
    "# outputs = encoder(encoder_inputs)\n",
    "# pooled_output = outputs[\"pooled_output\"]      # [batch_size, 768].\n",
    "# sequence_output = outputs[\"sequence_output\"]  # [batch_size, seq_length, 768].\n",
    "\n",
    "\n",
    "\n",
    "prepro_url = \"https://www.kaggle.com/models/tensorflow/bert/TensorFlow2/en-uncased-preprocess/3\"\n",
    "enc_url = \"https://www.kaggle.com/models/tensorflow/bert/TensorFlow2/en-uncased-l-12-h-768-a-12/4\"\n",
    "bert_prep_model = hub.KerasLayer(prepro_url)\n",
    "test_text = ['hello there', 'general kenobi']\n",
    "prepro_txt = bert_prep_model(test_text)\n",
    "# prepro_txt.keys()\n",
    "# bert_model = hub.KerasLayer(enc_url)\n",
    "# results = bert_model(prepro_txt)\n",
    "# results.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e0dd62c57984990aed96fa680953963",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.95k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\adity\\anaconda3\\envs\\myenv\\lib\\site-packages\\huggingface_hub\\file_download.py:159: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\adity\\.cache\\huggingface\\hub\\models--DeathReaper0965--t5-context-corrector. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbcf9b23fc414535b9631e70afef19ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77922e689219441bac318d36b55bf34a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/1.79k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e341b447a57a42469cd0883d80e2b0a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.38k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "474e939f662440f4944fa5c932851a16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/892M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from nltk import sent_tokenize\n",
    "\n",
    "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
    "\n",
    "\n",
    "# Load model and tokenizer\n",
    "cc_tokenizer = T5Tokenizer.from_pretrained(\"DeathReaper0965/t5-context-corrector\")\n",
    "cc_model = T5ForConditionalGeneration.from_pretrained(\"DeathReaper0965/t5-context-corrector\")\n",
    "\n",
    "# Utility function to correct context\n",
    "def correct_context(input_text, temperature=0.5):\n",
    "    # tokenize\n",
    "    batch = cc_tokenizer(input_text, truncation=True, padding='max_length', max_length=256, return_tensors=\"pt\")\n",
    "\n",
    "    # forward pass\n",
    "    results = cc_model.generate(**batch, max_length=256, num_beams=3, no_repeat_ngram_size=2, repetition_penalty=2.5, temperature=temperature,do_sample=True)\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Utility function to split the paragraph into multiple sentences\n",
    "def split_and_correct_context(sent):\n",
    "    sents = sent_tokenize(sent)\n",
    "    \n",
    "    final_sents = cc_tokenizer.batch_decode(correct_context(sents), \n",
    "                                            clean_up_tokenization_spaces=True, \n",
    "                                            skip_special_tokens=True)\n",
    "    \n",
    "    final_sents = \" \".join([final_sents[i].strip() for i in range(len(final_sents))])\n",
    "    \n",
    "    return final_sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Do you even know why I always need to change our checking account number? Because of security purposes.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_and_correct_context(\"Do you even know why I always need changed our checking account number. Because of securty purpos.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\adity\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt_tab.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tok2vec', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer', 'ner']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_key = nlp(r'''Social Inequality (The Estates System): French society was divided into three estates. The First Estate (clergy) and the Second Estate (nobility) enjoyed privileges, such as exemptions from taxes and special legal rights, while the Third Estate (commoners) paid most of the taxes and had little political power. The Third Estate, which made up about 98% of the population, included peasants, urban workers, and the bourgeoisie (middle class). The resentment of the inequalities between the estates contributed significantly to the revolutionary spirit.\n",
    "Financial Crisis: France was deeply in debt due to its involvement in expensive wars, particularly the American Revolution (1775–1783), and lavish spending by King Louis XVI and his court. The tax burden largely fell on the Third Estate, while the clergy and nobility were exempt. Efforts to reform the tax system were blocked by the privileged classes. Bad weather in the late 1780s caused crop failures, resulting in food shortages, high bread prices, and widespread hunger. This led to increased suffering for the common people.\n",
    "Weak Leadership (Louis XVI and Marie Antoinette): King Louis XVI was seen as an ineffective ruler who failed to address France’s financial problems. His indecisiveness and inability to implement necessary reforms weakened his authority. Queen Marie Antoinette, who was unpopular for her extravagant lifestyle and foreign origins, was often blamed for the financial crisis, further fueling discontent.\n",
    "Enlightenment Ideas: The Enlightenment was an intellectual movement that emphasized reason, individual rights, and the idea of equality before the law. Philosophers like Jean-Jacques Rousseau, Voltaire, and Baron de Montesquieu criticized absolute monarchy and aristocratic privileges. These ideas inspired many in the Third Estate, especially the bourgeoisie, who sought greater political influence and reform of the outdated system.\n",
    "Ineffective Government and Estates-General: By 1789, France’s financial situation had become so dire that Louis XVI called the Estates-General (a representative assembly) for the first time since 1614, to address the fiscal crisis. The Third Estate, feeling underrepresented and excluded from decision-making, eventually proclaimed itself the National Assembly and vowed to draft a new constitution, a move that challenged the authority of the king and sparked a political crisis.\n",
    "Economic Hardship and Unrest: With the economic difficulties and food shortages, bread prices soared, and many people could not afford basic food. This created widespread anger and unrest, particularly in urban areas. Many workers and artisans faced unemployment and poor living conditions, which further aggravated social tensions.\n",
    "Failure of Reform: Some attempts were made by the monarchy to implement reforms, such as calling the Estates-General or suggesting new tax policies, but these were either too little or too late. The reforms did not resolve the underlying economic and social issues, and the monarchy’s refusal to implement deeper changes contributed to the collapse of royal authority.\n",
    "The Influence of the American Revolution: The success of the American Revolution (1776) provided a model for challenging authority and achieving political change. The idea that a people could overthrow an oppressive government and establish a republic inspired many in France, particularly among the bourgeoisie and revolutionary thinkers.\n",
    "''')\n",
    "doc_ans = nlp(r'''Social Inequality: French society was divided into three estates. The First Estate consisted of the clergy, the Second Estate was made up of the nobility, and the Third Estate included peasants, city workers, and the bourgeoisie (middle class). The Third Estate made up about 98% of the population, but they were heavily taxed and had little political power, while the First and Second Estates enjoyed privileges. This created widespread frustration and resentment among the lower classes.\n",
    "Financial Crisis: By the late 1700s, France was in severe debt, primarily due to its involvement in expensive wars, like the American Revolution, and the lavish spending of King Louis XVI and his court. The government had to borrow large sums of money, leading to an economic crisis. The tax system was inefficient, and the burden fell on the common people, worsening their financial hardship.\n",
    "Enlightenment Ideas: The Enlightenment, a philosophical movement emphasizing reason, individual rights, and equality, influenced many French thinkers. Ideas about liberty, democracy, and the rights of man began to spread, encouraging people to question traditional authority and the monarchy. Thinkers like Rousseau, Voltaire, and Montesquieu inspired the desire for reform and change.\n",
    "Poor Harvests and Hunger: France suffered a series of bad harvests in the late 1780s, leading to food shortages, high bread prices, and widespread hunger. The harsh winters and poor agricultural conditions made life difficult for peasants and urban workers, which led to anger and unrest. The high price of bread, a staple food, was particularly damaging to the lower classes.\n",
    "Weak Leadership: King Louis XVI was seen as a weak and indecisive ruler. His inability to solve the financial crisis or address the grievances of the people made the monarchy appear ineffective. Queen Marie Antoinette was also unpopular, partly due to her lavish lifestyle, which contrasted sharply with the suffering of the common people.\n",
    "Estates-General and the National Assembly: In 1789, in an attempt to solve the financial crisis, Louis XVI called the Estates-General (a meeting of representatives from all three estates). The Third Estate, frustrated with their lack of power, broke away and declared themselves the National Assembly, signaling the start of a political revolution. They vowed to create a new constitution for France, leading to the formation of a revolutionary government.''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stops(doc):\n",
    "    return nlp(' '.join([token.text for token in doc if not token.is_stop]))\n",
    "def remove_stops_lem(doc):\n",
    "    return nlp(' '.join([token.lemma_ for token in doc if not token.is_stop]))\n",
    "def generate_bigrams(doc):\n",
    "    return [[i,j] for i,j in zip(doc,doc[1:])]\n",
    "def to_lower(doc):\n",
    "    return nlp(str(doc).lower())\n",
    "def remove_punct(doc):\n",
    "    return nlp(' '.join([token.text for token in doc if not token.is_punct]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigrams = generate_bigrams(doc_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Social Inequality ( Estates System ): French society divided estates . Estate ( clergy ) Second Estate ( nobility ) enjoyed privileges , exemptions taxes special legal rights , Estate ( commoners ) paid taxes little political power . Estate , 98 % population , included peasants , urban workers , bourgeoisie ( middle class ) . resentment inequalities estates contributed significantly revolutionary spirit . \n",
       " Financial Crisis : France deeply debt involvement expensive wars , particularly American Revolution ( 1775–1783 ) , lavish spending King Louis XVI court . tax burden largely fell Estate , clergy nobility exempt . Efforts reform tax system blocked privileged classes . Bad weather late 1780s caused crop failures , resulting food shortages , high bread prices , widespread hunger . led increased suffering common people . \n",
       " Weak Leadership ( Louis XVI Marie Antoinette ): King Louis XVI seen ineffective ruler failed address France financial problems . indecisiveness inability implement necessary reforms weakened authority . Queen Marie Antoinette , unpopular extravagant lifestyle foreign origins , blamed financial crisis , fueling discontent . \n",
       " Enlightenment Ideas : Enlightenment intellectual movement emphasized reason , individual rights , idea equality law . Philosophers like Jean - Jacques Rousseau , Voltaire , Baron de Montesquieu criticized absolute monarchy aristocratic privileges . ideas inspired Estate , especially bourgeoisie , sought greater political influence reform outdated system . \n",
       " Ineffective Government Estates - General : 1789 , France financial situation dire Louis XVI called Estates - General ( representative assembly ) time 1614 , address fiscal crisis . Estate , feeling underrepresented excluded decision - making , eventually proclaimed National Assembly vowed draft new constitution , challenged authority king sparked political crisis . \n",
       " Economic Hardship Unrest : economic difficulties food shortages , bread prices soared , people afford basic food . created widespread anger unrest , particularly urban areas . workers artisans faced unemployment poor living conditions , aggravated social tensions . \n",
       " Failure Reform : attempts monarchy implement reforms , calling Estates - General suggesting new tax policies , little late . reforms resolve underlying economic social issues , monarchy refusal implement deeper changes contributed collapse royal authority . \n",
       " Influence American Revolution : success American Revolution ( 1776 ) provided model challenging authority achieving political change . idea people overthrow oppressive government establish republic inspired France , particularly bourgeoisie revolutionary thinkers . "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_stops(doc_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Social Inequality : french society divide estate . Estate consist clergy , Second Estate nobility , Estate include peasant , city worker , bourgeoisie ( middle class ) . Estate 98 % population , heavily tax little political power , second Estates enjoy privilege . create widespread frustration resentment low class . \n",
       " Financial Crisis : late 1700 , France severe debt , primarily involvement expensive war , like American Revolution , lavish spending King Louis XVI court . government borrow large sum money , lead economic crisis . tax system inefficient , burden fall common people , worsen financial hardship . \n",
       " Enlightenment Ideas : Enlightenment , philosophical movement emphasize reason , individual right , equality , influence french thinker . idea liberty , democracy , right man begin spread , encourage people question traditional authority monarchy . thinker like Rousseau , Voltaire , Montesquieu inspire desire reform change . \n",
       " Poor Harvests Hunger : France suffer series bad harvest late 1780s , lead food shortage , high bread price , widespread hunger . harsh winter poor agricultural condition life difficult peasant urban worker , lead anger unrest . high price bread , staple food , particularly damaging low class . \n",
       " weak leadership : King Louis XVI see weak indecisive ruler . inability solve financial crisis address grievance people monarchy appear ineffective . Queen Marie Antoinette unpopular , partly lavish lifestyle , contrast sharply suffering common people . \n",
       " Estates - General National Assembly : 1789 , attempt solve financial crisis , Louis XVI call Estates - General ( meeting representative estate ) . Estate , frustrate lack power , break away declare National Assembly , signal start political revolution . vow create new constitution France , lead formation revolutionary government ."
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_stops_lem(doc_ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Social Inequality:,\n",
       " French society was divided into three estates.,\n",
       " The First Estate consisted of the clergy, the Second Estate was made up of the nobility, and the Third Estate included peasants, city workers, and the bourgeoisie (middle class).,\n",
       " The Third Estate made up about 98% of the population, but they were heavily taxed and had little political power, while the First and Second Estates enjoyed privileges.,\n",
       " This created widespread frustration and resentment among the lower classes.,\n",
       " Financial Crisis:,\n",
       " By the late 1700s, France was in severe debt, primarily due to its involvement in expensive wars, like the American Revolution, and the lavish spending of King Louis XVI and his court.,\n",
       " The government had to borrow large sums of money, leading to an economic crisis.,\n",
       " The tax system was inefficient, and the burden fell on the common people, worsening their financial hardship.,\n",
       " Enlightenment Ideas: The Enlightenment, a philosophical movement emphasizing reason, individual rights, and equality, influenced many French thinkers.,\n",
       " Ideas about liberty, democracy, and the rights of man began to spread, encouraging people to question traditional authority and the monarchy.,\n",
       " Thinkers like Rousseau, Voltaire, and Montesquieu inspired the desire for reform and change.,\n",
       " Poor Harvests and Hunger: France suffered a series of bad harvests in the late 1780s, leading to food shortages, high bread prices, and widespread hunger.,\n",
       " The harsh winters and poor agricultural conditions made life difficult for peasants and urban workers, which led to anger and unrest.,\n",
       " The high price of bread, a staple food, was particularly damaging to the lower classes.,\n",
       " Weak Leadership: King Louis XVI was seen as a weak and indecisive ruler.,\n",
       " His inability to solve the financial crisis or address the grievances of the people made the monarchy appear ineffective.,\n",
       " Queen Marie Antoinette was also unpopular, partly due to her lavish lifestyle, which contrasted sharply with the suffering of the common people.,\n",
       " Estates-General and the National Assembly: In 1789, in an attempt to solve the financial crisis, Louis XVI called the Estates-General (a meeting of representatives from all three estates).,\n",
       " The Third Estate, frustrated with their lack of power, broke away and declared themselves the National Assembly, signaling the start of a political revolution.,\n",
       " They vowed to create a new constitution for France, leading to the formation of a revolutionary government.]"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i for i in doc_ans.sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 50.0%\n"
     ]
    }
   ],
   "source": [
    "from fuzzywuzzy import fuzz\n",
    "\n",
    "# Key points from the answer key\n",
    "key_points = ['social inequality', 'financial crisis', 'Enlightenment ideas', 'weak leadership']\n",
    "\n",
    "# Student's answer\n",
    "student_answer = \"The financial issues and the Enlightenment caused unrest.\"\n",
    "\n",
    "# Preprocess\n",
    "student_answer = student_answer.lower()\n",
    "\n",
    "# Check matches\n",
    "score = 0\n",
    "for point in key_points:\n",
    "    if fuzz.partial_ratio(point.lower(), student_answer) > 80:  # Adjust threshold as needed\n",
    "        score += 1\n",
    "\n",
    "# Calculate percentage\n",
    "total_points = len(key_points)\n",
    "percentage = (score / total_points) * 100\n",
    "print(f\"Score: {percentage}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "social inequality ( estate system ): french society divide estate .\n",
      "estate ( clergy ) second estate ( nobility ) enjoy privilege , exemption taxis special legal right , estate ( commoner ) pay taxis little political power .\n",
      "estate , 98 % population , include peasant , urban worker , bourgeoisie ( middle class ) .\n",
      "resentment inequality estate contribute significantly revolutionary spirit . \n",
      "  \n",
      "financial crisis : france deeply debt involvement expensive war , particularly american revolution ( 1775–1783 ) , lavish spending king louis xvi court .\n",
      "tax burden largely fall estate , clergy nobility exempt .\n",
      "effort reform tax system block privileged class .\n",
      "bad weather late 1780 cause crop failure , result food shortage , high bread price , widespread hunger .\n",
      "lead increase suffer common people . \n",
      "  \n",
      "weak leadership ( louis xvi marie antoinette ): king louis xvi see ineffective ruler fail address france financial problem .\n",
      "indecisiveness inability implement necessary reform weaken authority .\n",
      "queen marie antoinette , unpopular extravagant lifestyle foreign origin , blame financial crisis , fuel discontent . \n",
      "  \n",
      "enlightenment idea : enlightenment intellectual movement emphasize reason , individual right , idea equality law .\n",
      "philosopher like jean - jacques rousseau , voltaire , baron de montesquieu criticize absolute monarchy aristocratic privilege .\n",
      "idea inspire estate , especially bourgeoisie , seek great political influence reform outdated system . \n",
      "  ineffective government estate - general : 1789 , france financial situation dire louis xvi call estate - general ( representative assembly ) time 1614 , address fiscal crisis .\n",
      "estate , feel underrepresented exclude decision - making , eventually proclaim national assembly vow draft new constitution , challenge authority king spark political crisis . \n",
      "  \n",
      "economic hardship unrest : economic difficulty food shortage , bread price soar , people afford basic food .\n",
      "create widespread anger unrest , particularly urban area .\n",
      "worker artisan face unemployment poor living condition , aggravate social tension . \n",
      "  \n",
      "failure reform : attempt monarchy implement reform , call estate - general suggest new tax policy , little late .\n",
      "reform resolve underlie economic social issue , monarchy refusal implement deep change contribute collapse royal authority . \n",
      "  \n",
      "influence american revolution : success american revolution ( 1776 ) provide model challenge authority achieve political change .\n",
      "idea people overthrow oppressive government establish republic inspire france , particularly bourgeoisie revolutionary thinker . \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for sentence in (remove_stops_lem(to_lower(doc_key))).sents:\n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Social  |  PROPN  |  Social\n",
      "Inequality  |  PROPN  |  Inequality\n",
      "(  |  PUNCT  |  (\n",
      "Estates  |  PROPN  |  Estates\n",
      "System  |  PROPN  |  System\n",
      "):  |  PUNCT  |  ):\n",
      "French  |  ADJ  |  french\n",
      "society  |  NOUN  |  society\n",
      "divided  |  VERB  |  divide\n",
      "estates  |  NOUN  |  estate\n",
      ".  |  PUNCT  |  .\n",
      "Estate  |  NOUN  |  estate\n",
      "(  |  PUNCT  |  (\n",
      "clergy  |  NOUN  |  clergy\n",
      ")  |  PUNCT  |  )\n",
      "Second  |  PROPN  |  Second\n",
      "Estate  |  PROPN  |  Estate\n",
      "(  |  PUNCT  |  (\n",
      "nobility  |  NOUN  |  nobility\n",
      ")  |  PUNCT  |  )\n",
      "enjoyed  |  VERB  |  enjoy\n",
      "privileges  |  NOUN  |  privilege\n",
      ",  |  PUNCT  |  ,\n",
      "exemptions  |  NOUN  |  exemption\n",
      "taxes  |  NOUN  |  taxis\n",
      "special  |  ADJ  |  special\n",
      "legal  |  ADJ  |  legal\n",
      "rights  |  NOUN  |  right\n",
      ",  |  PUNCT  |  ,\n",
      "Estate  |  PROPN  |  Estate\n",
      "(  |  PUNCT  |  (\n",
      "commoners  |  NOUN  |  commoner\n",
      ")  |  PUNCT  |  )\n",
      "paid  |  VERB  |  pay\n",
      "taxes  |  NOUN  |  taxis\n",
      "little  |  ADJ  |  little\n",
      "political  |  ADJ  |  political\n",
      "power  |  NOUN  |  power\n",
      ".  |  PUNCT  |  .\n",
      "Estate  |  NOUN  |  estate\n",
      ",  |  PUNCT  |  ,\n",
      "98  |  NUM  |  98\n",
      "%  |  NOUN  |  %\n",
      "population  |  NOUN  |  population\n",
      ",  |  PUNCT  |  ,\n",
      "included  |  VERB  |  include\n",
      "peasants  |  NOUN  |  peasant\n",
      ",  |  PUNCT  |  ,\n",
      "urban  |  ADJ  |  urban\n",
      "workers  |  NOUN  |  worker\n",
      ",  |  PUNCT  |  ,\n",
      "bourgeoisie  |  NOUN  |  bourgeoisie\n",
      "(  |  PUNCT  |  (\n",
      "middle  |  ADJ  |  middle\n",
      "class  |  NOUN  |  class\n",
      ")  |  PUNCT  |  )\n",
      ".  |  PUNCT  |  .\n",
      "resentment  |  NOUN  |  resentment\n",
      "inequalities  |  NOUN  |  inequality\n",
      "estates  |  NOUN  |  estate\n",
      "contributed  |  VERB  |  contribute\n",
      "significantly  |  ADV  |  significantly\n",
      "revolutionary  |  ADJ  |  revolutionary\n",
      "spirit  |  PROPN  |  spirit\n",
      ".  |  PUNCT  |  .\n",
      "\n",
      "   |  SPACE  |  \n",
      " \n",
      "Financial  |  PROPN  |  Financial\n",
      "Crisis  |  PROPN  |  Crisis\n",
      ":  |  PUNCT  |  :\n",
      "France  |  PROPN  |  France\n",
      "deeply  |  ADV  |  deeply\n",
      "debt  |  NOUN  |  debt\n",
      "involvement  |  NOUN  |  involvement\n",
      "expensive  |  ADJ  |  expensive\n",
      "wars  |  NOUN  |  war\n",
      ",  |  PUNCT  |  ,\n",
      "particularly  |  ADV  |  particularly\n",
      "American  |  PROPN  |  American\n",
      "Revolution  |  PROPN  |  Revolution\n",
      "(  |  PUNCT  |  (\n",
      "1775–1783  |  NUM  |  1775–1783\n",
      ")  |  PUNCT  |  )\n",
      ",  |  PUNCT  |  ,\n",
      "lavish  |  ADJ  |  lavish\n",
      "spending  |  VERB  |  spend\n",
      "King  |  PROPN  |  King\n",
      "Louis  |  PROPN  |  Louis\n",
      "XVI  |  PROPN  |  XVI\n",
      "court  |  NOUN  |  court\n",
      ".  |  PUNCT  |  .\n",
      "tax  |  NOUN  |  tax\n",
      "burden  |  NOUN  |  burden\n",
      "largely  |  ADV  |  largely\n",
      "fell  |  VERB  |  fall\n",
      "Estate  |  PROPN  |  Estate\n",
      ",  |  PUNCT  |  ,\n",
      "clergy  |  ADJ  |  clergy\n",
      "nobility  |  NOUN  |  nobility\n",
      "exempt  |  ADJ  |  exempt\n",
      ".  |  PUNCT  |  .\n",
      "Efforts  |  NOUN  |  effort\n",
      "reform  |  NOUN  |  reform\n",
      "tax  |  NOUN  |  tax\n",
      "system  |  NOUN  |  system\n",
      "blocked  |  VERB  |  block\n",
      "privileged  |  ADJ  |  privileged\n",
      "classes  |  NOUN  |  class\n",
      ".  |  PUNCT  |  .\n",
      "Bad  |  ADJ  |  bad\n",
      "weather  |  NOUN  |  weather\n",
      "late  |  ADJ  |  late\n",
      "1780s  |  NOUN  |  1780\n",
      "caused  |  VERB  |  cause\n",
      "crop  |  NOUN  |  crop\n",
      "failures  |  NOUN  |  failure\n",
      ",  |  PUNCT  |  ,\n",
      "resulting  |  VERB  |  result\n",
      "food  |  NOUN  |  food\n",
      "shortages  |  NOUN  |  shortage\n",
      ",  |  PUNCT  |  ,\n",
      "high  |  ADJ  |  high\n",
      "bread  |  NOUN  |  bread\n",
      "prices  |  NOUN  |  price\n",
      ",  |  PUNCT  |  ,\n",
      "widespread  |  ADJ  |  widespread\n",
      "hunger  |  NOUN  |  hunger\n",
      ".  |  PUNCT  |  .\n",
      "led  |  VERB  |  lead\n",
      "increased  |  VERB  |  increase\n",
      "suffering  |  VERB  |  suffer\n",
      "common  |  ADJ  |  common\n",
      "people  |  NOUN  |  people\n",
      ".  |  PUNCT  |  .\n",
      "\n",
      "   |  SPACE  |  \n",
      " \n",
      "Weak  |  PROPN  |  Weak\n",
      "Leadership  |  PROPN  |  Leadership\n",
      "(  |  PUNCT  |  (\n",
      "Louis  |  PROPN  |  Louis\n",
      "XVI  |  PROPN  |  XVI\n",
      "Marie  |  PROPN  |  Marie\n",
      "Antoinette  |  PROPN  |  Antoinette\n",
      "):  |  PUNCT  |  ):\n",
      "King  |  PROPN  |  King\n",
      "Louis  |  PROPN  |  Louis\n",
      "XVI  |  PROPN  |  XVI\n",
      "seen  |  VERB  |  see\n",
      "ineffective  |  ADJ  |  ineffective\n",
      "ruler  |  NOUN  |  ruler\n",
      "failed  |  VERB  |  fail\n",
      "address  |  NOUN  |  address\n",
      "France  |  PROPN  |  France\n",
      "financial  |  ADJ  |  financial\n",
      "problems  |  NOUN  |  problem\n",
      ".  |  PUNCT  |  .\n",
      "indecisiveness  |  NOUN  |  indecisiveness\n",
      "inability  |  NOUN  |  inability\n",
      "implement  |  VERB  |  implement\n",
      "necessary  |  ADJ  |  necessary\n",
      "reforms  |  NOUN  |  reform\n",
      "weakened  |  VERB  |  weaken\n",
      "authority  |  NOUN  |  authority\n",
      ".  |  PUNCT  |  .\n",
      "Queen  |  PROPN  |  Queen\n",
      "Marie  |  PROPN  |  Marie\n",
      "Antoinette  |  PROPN  |  Antoinette\n",
      ",  |  PUNCT  |  ,\n",
      "unpopular  |  ADJ  |  unpopular\n",
      "extravagant  |  ADJ  |  extravagant\n",
      "lifestyle  |  NOUN  |  lifestyle\n",
      "foreign  |  ADJ  |  foreign\n",
      "origins  |  NOUN  |  origin\n",
      ",  |  PUNCT  |  ,\n",
      "blamed  |  VERB  |  blame\n",
      "financial  |  ADJ  |  financial\n",
      "crisis  |  NOUN  |  crisis\n",
      ",  |  PUNCT  |  ,\n",
      "fueling  |  VERB  |  fuel\n",
      "discontent  |  NOUN  |  discontent\n",
      ".  |  PUNCT  |  .\n",
      "\n",
      "   |  SPACE  |  \n",
      " \n",
      "Enlightenment  |  PROPN  |  Enlightenment\n",
      "Ideas  |  PROPN  |  Ideas\n",
      ":  |  PUNCT  |  :\n",
      "Enlightenment  |  PROPN  |  Enlightenment\n",
      "intellectual  |  ADJ  |  intellectual\n",
      "movement  |  NOUN  |  movement\n",
      "emphasized  |  VERB  |  emphasize\n",
      "reason  |  NOUN  |  reason\n",
      ",  |  PUNCT  |  ,\n",
      "individual  |  ADJ  |  individual\n",
      "rights  |  NOUN  |  right\n",
      ",  |  PUNCT  |  ,\n",
      "idea  |  NOUN  |  idea\n",
      "equality  |  NOUN  |  equality\n",
      "law  |  NOUN  |  law\n",
      ".  |  PUNCT  |  .\n",
      "Philosophers  |  NOUN  |  philosopher\n",
      "like  |  ADP  |  like\n",
      "Jean  |  PROPN  |  Jean\n",
      "-  |  PUNCT  |  -\n",
      "Jacques  |  PROPN  |  Jacques\n",
      "Rousseau  |  PROPN  |  Rousseau\n",
      ",  |  PUNCT  |  ,\n",
      "Voltaire  |  PROPN  |  Voltaire\n",
      ",  |  PUNCT  |  ,\n",
      "Baron  |  PROPN  |  Baron\n",
      "de  |  PROPN  |  de\n",
      "Montesquieu  |  PROPN  |  Montesquieu\n",
      "criticized  |  VERB  |  criticize\n",
      "absolute  |  ADJ  |  absolute\n",
      "monarchy  |  ADJ  |  monarchy\n",
      "aristocratic  |  ADJ  |  aristocratic\n",
      "privileges  |  NOUN  |  privilege\n",
      ".  |  PUNCT  |  .\n",
      "ideas  |  NOUN  |  idea\n",
      "inspired  |  VERB  |  inspire\n",
      "Estate  |  PROPN  |  Estate\n",
      ",  |  PUNCT  |  ,\n",
      "especially  |  ADV  |  especially\n",
      "bourgeoisie  |  NOUN  |  bourgeoisie\n",
      ",  |  PUNCT  |  ,\n",
      "sought  |  VERB  |  seek\n",
      "greater  |  ADJ  |  great\n",
      "political  |  ADJ  |  political\n",
      "influence  |  NOUN  |  influence\n",
      "reform  |  NOUN  |  reform\n",
      "outdated  |  ADJ  |  outdated\n",
      "system  |  NOUN  |  system\n",
      ".  |  PUNCT  |  .\n",
      "\n",
      "   |  SPACE  |  \n",
      " \n",
      "Ineffective  |  PROPN  |  Ineffective\n",
      "Government  |  PROPN  |  Government\n",
      "Estates  |  PROPN  |  Estates\n",
      "-  |  PUNCT  |  -\n",
      "General  |  PROPN  |  General\n",
      ":  |  PUNCT  |  :\n",
      "1789  |  NUM  |  1789\n",
      ",  |  PUNCT  |  ,\n",
      "France  |  PROPN  |  France\n",
      "financial  |  ADJ  |  financial\n",
      "situation  |  NOUN  |  situation\n",
      "dire  |  ADJ  |  dire\n",
      "Louis  |  PROPN  |  Louis\n",
      "XVI  |  PROPN  |  XVI\n",
      "called  |  VERB  |  call\n",
      "Estates  |  PROPN  |  Estates\n",
      "-  |  PUNCT  |  -\n",
      "General  |  PROPN  |  General\n",
      "(  |  PUNCT  |  (\n",
      "representative  |  ADJ  |  representative\n",
      "assembly  |  NOUN  |  assembly\n",
      ")  |  PUNCT  |  )\n",
      "time  |  NOUN  |  time\n",
      "1614  |  NUM  |  1614\n",
      ",  |  PUNCT  |  ,\n",
      "address  |  NOUN  |  address\n",
      "fiscal  |  ADJ  |  fiscal\n",
      "crisis  |  NOUN  |  crisis\n",
      ".  |  PUNCT  |  .\n",
      "Estate  |  NOUN  |  estate\n",
      ",  |  PUNCT  |  ,\n",
      "feeling  |  VERB  |  feel\n",
      "underrepresented  |  ADJ  |  underrepresented\n",
      "excluded  |  VERB  |  exclude\n",
      "decision  |  NOUN  |  decision\n",
      "-  |  PUNCT  |  -\n",
      "making  |  NOUN  |  making\n",
      ",  |  PUNCT  |  ,\n",
      "eventually  |  ADV  |  eventually\n",
      "proclaimed  |  VERB  |  proclaim\n",
      "National  |  PROPN  |  National\n",
      "Assembly  |  PROPN  |  Assembly\n",
      "vowed  |  VERB  |  vow\n",
      "draft  |  VERB  |  draft\n",
      "new  |  ADJ  |  new\n",
      "constitution  |  NOUN  |  constitution\n",
      ",  |  PUNCT  |  ,\n",
      "challenged  |  VERB  |  challenge\n",
      "authority  |  NOUN  |  authority\n",
      "king  |  NOUN  |  king\n",
      "sparked  |  VERB  |  spark\n",
      "political  |  ADJ  |  political\n",
      "crisis  |  NOUN  |  crisis\n",
      ".  |  PUNCT  |  .\n",
      "\n",
      "   |  SPACE  |  \n",
      " \n",
      "Economic  |  PROPN  |  Economic\n",
      "Hardship  |  PROPN  |  Hardship\n",
      "Unrest  |  PROPN  |  Unrest\n",
      ":  |  PUNCT  |  :\n",
      "economic  |  ADJ  |  economic\n",
      "difficulties  |  NOUN  |  difficulty\n",
      "food  |  NOUN  |  food\n",
      "shortages  |  NOUN  |  shortage\n",
      ",  |  PUNCT  |  ,\n",
      "bread  |  NOUN  |  bread\n",
      "prices  |  NOUN  |  price\n",
      "soared  |  VERB  |  soar\n",
      ",  |  PUNCT  |  ,\n",
      "people  |  NOUN  |  people\n",
      "afford  |  VERB  |  afford\n",
      "basic  |  ADJ  |  basic\n",
      "food  |  NOUN  |  food\n",
      ".  |  PUNCT  |  .\n",
      "created  |  VERB  |  create\n",
      "widespread  |  ADJ  |  widespread\n",
      "anger  |  NOUN  |  anger\n",
      "unrest  |  NOUN  |  unrest\n",
      ",  |  PUNCT  |  ,\n",
      "particularly  |  ADV  |  particularly\n",
      "urban  |  ADJ  |  urban\n",
      "areas  |  NOUN  |  area\n",
      ".  |  PUNCT  |  .\n",
      "workers  |  NOUN  |  worker\n",
      "artisans  |  NOUN  |  artisan\n",
      "faced  |  VERB  |  face\n",
      "unemployment  |  NOUN  |  unemployment\n",
      "poor  |  ADJ  |  poor\n",
      "living  |  NOUN  |  living\n",
      "conditions  |  NOUN  |  condition\n",
      ",  |  PUNCT  |  ,\n",
      "aggravated  |  VERB  |  aggravate\n",
      "social  |  ADJ  |  social\n",
      "tensions  |  NOUN  |  tension\n",
      ".  |  PUNCT  |  .\n",
      "\n",
      "   |  SPACE  |  \n",
      " \n",
      "Failure  |  PROPN  |  Failure\n",
      "Reform  |  PROPN  |  Reform\n",
      ":  |  PUNCT  |  :\n",
      "attempts  |  NOUN  |  attempt\n",
      "monarchy  |  NOUN  |  monarchy\n",
      "implement  |  VERB  |  implement\n",
      "reforms  |  NOUN  |  reform\n",
      ",  |  PUNCT  |  ,\n",
      "calling  |  VERB  |  call\n",
      "Estates  |  PROPN  |  Estates\n",
      "-  |  PUNCT  |  -\n",
      "General  |  PROPN  |  General\n",
      "suggesting  |  VERB  |  suggest\n",
      "new  |  ADJ  |  new\n",
      "tax  |  NOUN  |  tax\n",
      "policies  |  NOUN  |  policy\n",
      ",  |  PUNCT  |  ,\n",
      "little  |  ADV  |  little\n",
      "late  |  ADJ  |  late\n",
      ".  |  PUNCT  |  .\n",
      "reforms  |  NOUN  |  reform\n",
      "resolve  |  VERB  |  resolve\n",
      "underlying  |  VERB  |  underlie\n",
      "economic  |  ADJ  |  economic\n",
      "social  |  ADJ  |  social\n",
      "issues  |  NOUN  |  issue\n",
      ",  |  PUNCT  |  ,\n",
      "monarchy  |  ADJ  |  monarchy\n",
      "refusal  |  NOUN  |  refusal\n",
      "implement  |  VERB  |  implement\n",
      "deeper  |  ADJ  |  deep\n",
      "changes  |  NOUN  |  change\n",
      "contributed  |  VERB  |  contribute\n",
      "collapse  |  NOUN  |  collapse\n",
      "royal  |  ADJ  |  royal\n",
      "authority  |  NOUN  |  authority\n",
      ".  |  PUNCT  |  .\n",
      "\n",
      "   |  SPACE  |  \n",
      " \n",
      "Influence  |  PROPN  |  Influence\n",
      "American  |  PROPN  |  American\n",
      "Revolution  |  PROPN  |  Revolution\n",
      ":  |  PUNCT  |  :\n",
      "success  |  NOUN  |  success\n",
      "American  |  PROPN  |  American\n",
      "Revolution  |  PROPN  |  Revolution\n",
      "(  |  PUNCT  |  (\n",
      "1776  |  NUM  |  1776\n",
      ")  |  PUNCT  |  )\n",
      "provided  |  VERB  |  provide\n",
      "model  |  NOUN  |  model\n",
      "challenging  |  VERB  |  challenge\n",
      "authority  |  NOUN  |  authority\n",
      "achieving  |  VERB  |  achieve\n",
      "political  |  ADJ  |  political\n",
      "change  |  NOUN  |  change\n",
      ".  |  PUNCT  |  .\n",
      "idea  |  NOUN  |  idea\n",
      "people  |  NOUN  |  people\n",
      "overthrow  |  VERB  |  overthrow\n",
      "oppressive  |  ADJ  |  oppressive\n",
      "government  |  NOUN  |  government\n",
      "establish  |  NOUN  |  establish\n",
      "republic  |  NOUN  |  republic\n",
      "inspired  |  VERB  |  inspire\n",
      "France  |  PROPN  |  France\n",
      ",  |  PUNCT  |  ,\n",
      "particularly  |  ADV  |  particularly\n",
      "bourgeoisie  |  VERB  |  bourgeoisie\n",
      "revolutionary  |  ADJ  |  revolutionary\n",
      "thinkers  |  NOUN  |  thinker\n",
      ".  |  PUNCT  |  .\n",
      "\n",
      "  |  SPACE  |  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for token in doc_key:\n",
    "    print(token, \" | \", token.pos_, \" | \", token.lemma_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello  |  INTJ  |  hello\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"hello \")\n",
    "for token in doc:\n",
    "    print(token, \" | \", token.pos_, \" | \", token.lemma_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity: 0.7745966692414836\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Example preprocessing\n",
    "vectorizer = TfidfVectorizer()\n",
    "answer_key = 'war had happened in 1882'\n",
    "student_answer = 'the war took place in 1882'\n",
    "answer_key_vector = vectorizer.fit_transform([answer_key])\n",
    "student_answer_vector = vectorizer.transform([student_answer])\n",
    "\n",
    "# Similarity score\n",
    "similarity = cosine_similarity(answer_key_vector, student_answer_vector)\n",
    "print(\"Similarity:\", similarity[0][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")  # Load a small English language model\n",
    "\n",
    "def summarize(text, num_sentences=3):\n",
    "    doc = nlp(text)\n",
    "\n",
    "    # Calculate sentence scores based on word frequency and sentence length\n",
    "    sentence_scores = {}\n",
    "    for sent in doc.sents:\n",
    "        score = 0\n",
    "        for token in sent:\n",
    "            score += token.lemma_.count(\"_\")  # Count underscores in lemmas as a simple measure of importance\n",
    "        sentence_scores[sent] = score / len(sent)\n",
    "\n",
    "    # Sort sentences by score and return the top N\n",
    "    sorted_sentences = sorted(sentence_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "    return [str(sent) for sent, score in sorted_sentences[:num_sentences]]\n",
    "\n",
    "'''\n",
    "# no\n",
    "def bigram_similarity(sent1, sent2):\n",
    "    doc1 = nlp(sent1)\n",
    "    doc2 = nlp(sent2)\n",
    "\n",
    "    bigrams1 = [(doc1[i].lemma_, doc1[i+1].lemma_) for i in range(len(doc1)-1)]\n",
    "    bigrams2 = [(doc2[i].lemma_, doc2[i+1].lemma_) for i in range(len(doc2)-1)]\n",
    "\n",
    "    common_bigrams = set(bigrams1) & set(bigrams2)\n",
    "    return len(common_bigrams) / ((len(bigrams1) + len(bigrams2)) / 2)\n",
    "# no\n",
    "def synonym_similarity(sent1, sent2):\n",
    "    doc1 = nlp(sent1)\n",
    "    doc2 = nlp(sent2)\n",
    "\n",
    "    similarity_score = 0\n",
    "    for token1 in doc1:\n",
    "        for token2 in doc2:\n",
    "            # Check for exact match\n",
    "            if token1.text.lower() == token2.text.lower():\n",
    "                similarity_score += 1\n",
    "                break\n",
    "\n",
    "            # Check for synonyms using WordNet\n",
    "            synsets1 = wordnet.synsets(token1.text.lower())\n",
    "            synsets2 = wordnet.synsets(token2.text.lower())\n",
    "            \n",
    "            if synsets1 and synsets2:  # Ensure that both tokens have synsets\n",
    "                # Iterate through synsets of both tokens and compute similarity\n",
    "                for synset1 in synsets1:\n",
    "                    for synset2 in synsets2:\n",
    "                        similarity = synset1.wup_similarity(synset2)\n",
    "                        if similarity and similarity > 0.5:  # Only count strong similarities\n",
    "                            similarity_score += similarity\n",
    "                            break\n",
    "\n",
    "    return similarity_score / (len(doc1) + len(doc2)) if (len(doc1) + len(doc2)) > 0 else 0\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_synonyms(word):\n",
    "    synonyms = []\n",
    "    for token in nlp.vocab:\n",
    "        if token.has_vector and token.is_alpha and token.text.lower() != word.lower():\n",
    "            similarity = token.similarity(nlp(word)[0])\n",
    "            if similarity > 0.7:  # Threshold for synonym similarity\n",
    "                synonyms.append(token.text)\n",
    "    return synonyms\n",
    "\n",
    "def calculate_synonym_similarity(true_answer, student_answer):\n",
    "    true_tokens = [token.text.lower() for token in nlp(true_answer) if token.is_alpha]\n",
    "    student_tokens = [token.text.lower() for token in nlp(student_answer) if token.is_alpha]\n",
    "\n",
    "    match_count = 0\n",
    "\n",
    "    for student_word in student_tokens:\n",
    "        if student_word in true_tokens:\n",
    "            match_count += 1\n",
    "        else:\n",
    "            synonyms = generate_synonyms(student_word)\n",
    "            match_count += sum(1 for synonym in synonyms if synonym in true_tokens)\n",
    "\n",
    "    avg_length = (len(true_tokens) + len(student_tokens)) / 2\n",
    "    synonym_similarity = match_count / avg_length if avg_length > 0 else 0\n",
    "    return synonym_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5454545454545454"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_synonym_similarity(\"she made some cake for me\",\"she baked me a cake\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bigram Similarity Score: 0.25\n"
     ]
    }
   ],
   "source": [
    "def generate_bigrams(word_list):\n",
    "    return [(word_list[i], word_list[i + 1]) for i in range(len(word_list) - 1)]\n",
    "\n",
    "def bigram_similarity(text1, text2):\n",
    "    list1 = text1.split()\n",
    "    list2 = text2.split()\n",
    "    bigrams1 = generate_bigrams(list1)\n",
    "    bigrams2 = generate_bigrams(list2)\n",
    "    \n",
    "    set_bigrams1 = set(bigrams1)\n",
    "    set_bigrams2 = set(bigrams2)\n",
    "    \n",
    "    common_bigrams = set_bigrams1.intersection(set_bigrams2)\n",
    "    common_count = len(common_bigrams)\n",
    "    \n",
    "    avg_bigram_length = (len(set_bigrams1) + len(set_bigrams2)) / 2.0\n",
    "    \n",
    "    similarity_score = common_count / avg_bigram_length if avg_bigram_length > 0 else 0    \n",
    "    return similarity_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "text1 = \"The quick brown fox jumps over the lazy dog\"\n",
    "text2 = \"A fast brown fox leaps over the sleeping dog\"\n",
    "similarity = bigram_similarity(text1, text2)\n",
    "print(f\"Bigram Similarity Score: {similarity:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_similarity(text1, text2):\n",
    "    return 0.1 * bigram_similarity(text1, text2) + 0.2 * calculate_synonym_similarity(text1, text2) + 0.7 * cos_similarity(text1, text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5454545454545454"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_synonym_similarity(\"she made some cake for me\",\"she baked me a cake\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('The', 'quick'), ('quick', 'brown'), ('brown', 'fox'), ('fox', 'jumps'), ('jumps', 'over'), ('over', 'the'), ('the', 'lazy'), ('lazy', 'dog')]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.25"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1 = \"The quick brown fox jumps over the lazy dog\"\n",
    "text2 = \"A fast brown fox leaps over the sleeping dog\"\n",
    "bigram_similarity_(text1.split(), text2.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('paris', 'capital'), ('capital', 'france')]\n",
      "[('france', 'capital'), ('capital', 'paris')]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_similarity(\"paris is the capital of france\", \"france's capital is paris\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] 100.0% 1662.8/1662.8MB downloaded\n",
      "[('great', 0.7291509509086609), ('bad', 0.7190050482749939), ('terrific', 0.688911497592926), ('decent', 0.6837348937988281), ('nice', 0.6836092472076416), ('excellent', 0.6442928910255432), ('fantastic', 0.6407778263092041), ('better', 0.6120728850364685), ('solid', 0.5806034803390503), ('lousy', 0.576420247554779)]\n"
     ]
    }
   ],
   "source": [
    "import gensim.downloader as api\n",
    "model = api.load(\"word2vec-google-news-300\")\n",
    "word = \"good\"\n",
    "similar_words = model.most_similar(word, topn=10)\n",
    "print(similar_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet\n",
    "'''\n",
    "def generate_synonyms_(word):\n",
    "    synonyms = set()\n",
    "    for syn in wordnet.synsets(word):\n",
    "        for lemma in syn.lemmas():\n",
    "            synonyms.add(lemma.name())\n",
    "    return synonyms\n",
    "\n",
    "def synonym_similarity_(student_answer, true_answer):\n",
    "    # Step 1: Initialize matching count\n",
    "    matching_count = 0\n",
    "    \n",
    "    # Step 2: Convert true_answer to a set for faster matching\n",
    "    true_answer_set = set(true_answer)\n",
    "    \n",
    "    # Step 3: Direct match between student answer and true answer\n",
    "    for word in student_answer:\n",
    "        if word in true_answer_set:\n",
    "            matching_count += 1\n",
    "        else:\n",
    "            # Step 4: Generate synonyms if the word does not directly match\n",
    "            synonyms = generate_synonyms_(word)\n",
    "            if synonyms.intersection(true_answer_set):\n",
    "                matching_count += 1\n",
    "    \n",
    "    # Step 5: Calculate average document length\n",
    "    average_length = (len(student_answer) + len(true_answer)) / 2.0\n",
    "    \n",
    "    # Step 6: Calculate synonym similarity\n",
    "    similarity_score = matching_count / average_length\n",
    "    \n",
    "    return similarity_score\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "student_text = \"The quick brown fox leaps over the sleeping dog\"\n",
    "true_text = \"A fast brown fox jumps over a lazy dog\"\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "student_answer = [word.lower() for word in word_tokenize(student_text) if word.isalnum() and word.lower() not in stop_words]\n",
    "true_answer = [word.lower() for word in word_tokenize(true_text) if word.isalnum() and word.lower() not in stop_words]\n",
    "calculate_synonym_similarity(' '.join(student_answer), ' '.join(true_answer))\n",
    "# synonym_similarity_(student_text, true_text)\n",
    "# print(f\"Synonym Similarity Score: {similarity:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('data/x.csv')\n",
    "df.columns = ['text1', 'text2', 'label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text):\n",
    "    return \" \".join([word for word in text.split() if word.lower() not in nlp.Defaults.stop_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    cos_similarity  cos_similarity1  avg_similarity  label\n",
      "0         0.768834         0.764900        0.652470      1\n",
      "1         0.794583         0.802847        0.695494      1\n",
      "2         0.948046         0.885200        0.777918      1\n",
      "3         0.805450         0.737930        0.592387      1\n",
      "4         0.922186         0.942187        0.789844      1\n",
      "5         0.875049         0.826690        0.743848      1\n",
      "6         0.938559         0.820099        0.799849      1\n",
      "7         0.874267         0.820294        0.673525      1\n",
      "8         0.928758         0.970741        0.816797      1\n",
      "9         0.588683         0.543169        0.582078      0\n",
      "10        0.829079         0.807025        0.790355      0\n",
      "11        0.445494         0.433787        0.434923      0\n",
      "12        0.457403         0.383740        0.420182      0\n",
      "13        0.772969         0.741973        0.778002      0\n",
      "14        0.485465         0.476508        0.370595      0\n",
      "15        0.451189         0.380125        0.447146      0\n",
      "16        0.704081         0.790220        0.621528      0\n",
      "17        0.518880         0.550058        0.485267      0\n",
      "18        0.790994         0.724218        0.790619      0\n"
     ]
    }
   ],
   "source": [
    "df['cos_similarity'] = df.apply(lambda row: cos_similarity((row['text1']), (row['text2'])), axis=1)\n",
    "df['cos_similarity1'] = df.apply(lambda row: cos_similarity(remove_stopwords(row['text1']), remove_stopwords(row['text2'])), axis=1)\n",
    "df['avg_similarity'] = df.apply(lambda row: avg_similarity(row['text1'], row['text2']), axis=1)\n",
    "\n",
    "print(df[['cos_similarity', 'cos_similarity1', 'avg_similarity', 'label']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')  # Lightweight model for sentence similarity\n",
    "sentence1 = \"She enjoys reading books in her free time.\"\n",
    "sentence2 = \"In her leisure hours, she likes to read books.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute embeddings\n",
    "def cos_similarity(sentence1, sentence2):\n",
    "    embedding1 = model.encode(sentence1)\n",
    "    embedding2 = model.encode(sentence2)\n",
    "    # Calculate cosine similarity\n",
    "    similarity = cosine_similarity([embedding1], [embedding2])[0][0]\n",
    "    return similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\adity\\anaconda3\\envs\\myenv\\lib\\site-packages\\transformers\\models\\auto\\tokenization_auto.py:796: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28a2e00a9d4f4729aa7a07a2bacfe0e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.89k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\adity\\anaconda3\\envs\\myenv\\lib\\site-packages\\huggingface_hub\\file_download.py:159: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\adity\\.cache\\huggingface\\hub\\models--prithivida--grammar_error_correcter_v1. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e3188276f8346e2a5397d2f6b36d04f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.39k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "334186de4a364f29b45c433d0a51be75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6919947edba4cfcb109cd18cf576b21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "defc9e44abe94752b4f2b823e73a8524",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/1.79k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\adity\\anaconda3\\envs\\myenv\\lib\\site-packages\\transformers\\models\\auto\\auto_factory.py:471: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acae3d0a2cae4f08a958ff9832a04ee2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/892M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Gramformer] Grammar error correct/highlight model loaded..\n"
     ]
    }
   ],
   "source": [
    "from gramformer import Gramformer\n",
    "gf = Gramformer(models=1, use_gpu=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'I will count on ya.'}"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gf.correct(\"I will counting on ya\", max_candidates=1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
