{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Context correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    }
   ],
   "source": [
    "from nltk import sent_tokenize\n",
    "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
    "\n",
    "# Load model and tokenizer\n",
    "cc_tokenizer = T5Tokenizer.from_pretrained(\"DeathReaper0965/t5-context-corrector\")\n",
    "cc_model = T5ForConditionalGeneration.from_pretrained(\"DeathReaper0965/t5-context-corrector\")\n",
    "\n",
    "# Utility function to correct context\n",
    "def correct_context(input_text, temperature=0.5):\n",
    "    # tokenize\n",
    "    batch = cc_tokenizer(input_text, truncation=True, padding='max_length', max_length=256, return_tensors=\"pt\")\n",
    "\n",
    "    # forward pass\n",
    "    results = cc_model.generate(**batch, max_length=256, num_beams=3, no_repeat_ngram_size=2, repetition_penalty=2.5, temperature=temperature,do_sample=True)\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Utility function to split the paragraph into multiple sentences\n",
    "def split_and_correct_context(sent):\n",
    "    sents = sent_tokenize(sent)\n",
    "    \n",
    "    final_sents = cc_tokenizer.batch_decode(correct_context(sents), \n",
    "                                            clean_up_tokenization_spaces=True, \n",
    "                                            skip_special_tokens=True)\n",
    "    \n",
    "    final_sents = \" \".join([final_sents[i].strip() for i in range(len(final_sents))])\n",
    "    \n",
    "    return final_sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\adity\\anaconda3\\envs\\myenv\\lib\\site-packages\\transformers\\models\\auto\\tokenization_auto.py:796: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\adity\\anaconda3\\envs\\myenv\\lib\\site-packages\\transformers\\models\\auto\\auto_factory.py:471: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Gramformer] Grammar error correct/highlight model loaded..\n"
     ]
    }
   ],
   "source": [
    "from gramformer import Gramformer\n",
    "gf = Gramformer(models=1, use_gpu=False)\n",
    "def correct_grammar(text):\n",
    "    return list(gf.correct(text, max_candidates=1))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12/15/2024 10:50:17 - INFO - happytransformer.happy_transformer -   Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "from happytransformer import HappyTextToText, TTSettings\n",
    "happy_tt = HappyTextToText(\"T5\", \"vennify/t5-base-grammar-correction\")\n",
    "\n",
    "args = TTSettings(num_beams=5, min_length=1)\n",
    "def correct_grammar_2(text):\n",
    "    return happy_tt.generate_text(f\"grammar: {text}\", args=args).text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synonyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def generate_synonyms(word):\n",
    "    synonyms = []\n",
    "    for token in nlp.vocab:\n",
    "        if token.has_vector and token.is_alpha and token.text.lower() != word.lower():\n",
    "            similarity = token.similarity(nlp(word)[0])\n",
    "            if similarity > 0.7:  # Threshold for synonym similarity\n",
    "                synonyms.append(token.text)\n",
    "    return synonyms\n",
    "\n",
    "def calculate_synonym_similarity(true_answer, student_answer):\n",
    "    true_tokens = [token.text.lower() for token in nlp(true_answer) if token.is_alpha]\n",
    "    student_tokens = [token.text.lower() for token in nlp(student_answer) if token.is_alpha]\n",
    "\n",
    "    match_count = 0\n",
    "\n",
    "    for student_word in student_tokens:\n",
    "        if student_word in true_tokens:\n",
    "            match_count += 1\n",
    "        else:\n",
    "            synonyms = generate_synonyms(student_word)\n",
    "            match_count += sum(1 for synonym in synonyms if synonym in true_tokens)\n",
    "\n",
    "    avg_length = (len(true_tokens) + len(student_tokens)) / 2\n",
    "    synonym_similarity = match_count / avg_length if avg_length > 0 else 0\n",
    "    return synonym_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_bigrams(word_list):\n",
    "    return [(word_list[i], word_list[i + 1]) for i in range(len(word_list) - 1)]\n",
    "\n",
    "def bigram_similarity(text1, text2):\n",
    "    list1 = text1.split()\n",
    "    list2 = text2.split()\n",
    "    bigrams1 = generate_bigrams(list1)\n",
    "    bigrams2 = generate_bigrams(list2)\n",
    "    \n",
    "    set_bigrams1 = set(bigrams1)\n",
    "    set_bigrams2 = set(bigrams2)\n",
    "    \n",
    "    common_bigrams = set_bigrams1.intersection(set_bigrams2)\n",
    "    common_count = len(common_bigrams)\n",
    "    \n",
    "    avg_bigram_length = (len(set_bigrams1) + len(set_bigrams2)) / 2.0\n",
    "    \n",
    "    similarity_score = common_count / avg_bigram_length if avg_bigram_length > 0 else 0    \n",
    "    return similarity_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "def cos_similarity(sentence1, sentence2):\n",
    "    embedding1 = model.encode(sentence1, show_progress_bar=False)\n",
    "    embedding2 = model.encode(sentence2, show_progress_bar=False)\n",
    "    similarity = cosine_similarity([embedding1], [embedding2])[0][0]\n",
    "    return similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_similarity(text1, text2):\n",
    "    return 0.1 * bigram_similarity(text1, text2) + 0.2 * calculate_synonym_similarity(text1, text2) + 0.7 * cos_similarity(text1, text2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text):\n",
    "    return \" \".join([word.lower() for word in text.split() if word.lower() not in nlp.Defaults.stop_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_text(text):\n",
    "    return \" \".join([word.lemma_ for word in nlp(text)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    text = lemmatize_text(text)\n",
    "    text = remove_stopwords(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spelling correction (only for answers with few words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "fix_spelling = pipeline(\"text2text-generation\",model=\"oliverguhr/spelling-correction-english-base\")\n",
    "\n",
    "def correct_spelling(text):\n",
    "    return fix_spelling(f\"{text}\",max_length=2048)[0]['generated_text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing 2 sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mitochondria. mitochondria.\n",
      "mitochondria. mitochondria.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fffca1b9309a4f08b838be1e7fc3a216",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b65975262f9440990581e1f6f25b5d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.9000000834465027"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1 = \"mitochondria\"\n",
    "s2 = \"mitochondrai\"\n",
    "s1, s2 = correct_spelling(s1), correct_spelling(s2)\n",
    "print(s1, s2)\n",
    "s1, s2 = correct_grammar(s1), correct_grammar(s2)\n",
    "print(s1, s2)\n",
    "avg_similarity(s1, s2)#.round()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paragraph summarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize(text, num_sentences=3):\n",
    "    doc = nlp(text)\n",
    "\n",
    "    # Calculate sentence scores based on word frequency and sentence length\n",
    "    sentence_scores = {}\n",
    "    for sent in doc.sents:\n",
    "        score = 0\n",
    "        for token in sent:\n",
    "            score += token.lemma_.count(\"_\")  # Count underscores in lemmas as a simple measure of importance\n",
    "        sentence_scores[sent] = score / len(sent)\n",
    "\n",
    "    # Sort sentences by score and return the top N\n",
    "    sorted_sentences = sorted(sentence_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "    return [str(sent) for sent, score in sorted_sentences[:num_sentences]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimenting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_ans = nlp(r'''Social Inequality (The Estates System): French society was divided into three estates. The First Estate (clergy) and the Second Estate (nobility) enjoyed privileges, such as exemptions from taxes and special legal rights, while the Third Estate (commoners) paid most of the taxes and had little political power. The Third Estate, which made up about 98% of the population, included peasants, urban workers, and the bourgeoisie (middle class). The resentment of the inequalities between the estates contributed significantly to the revolutionary spirit.\n",
    "Financial Crisis: France was deeply in debt due to its involvement in expensive wars, particularly the American Revolution (1775–1783), and lavish spending by King Louis XVI and his court. The tax burden largely fell on the Third Estate, while the clergy and nobility were exempt. Efforts to reform the tax system were blocked by the privileged classes. Bad weather in the late 1780s caused crop failures, resulting in food shortages, high bread prices, and widespread hunger. This led to increased suffering for the common people.\n",
    "Weak Leadership (Louis XVI and Marie Antoinette): King Louis XVI was seen as an ineffective ruler who failed to address France’s financial problems. His indecisiveness and inability to implement necessary reforms weakened his authority. Queen Marie Antoinette, who was unpopular for her extravagant lifestyle and foreign origins, was often blamed for the financial crisis, further fueling discontent.\n",
    "Enlightenment Ideas: The Enlightenment was an intellectual movement that emphasized reason, individual rights, and the idea of equality before the law. Philosophers like Jean-Jacques Rousseau, Voltaire, and Baron de Montesquieu criticized absolute monarchy and aristocratic privileges. These ideas inspired many in the Third Estate, especially the bourgeoisie, who sought greater political influence and reform of the outdated system.\n",
    "Ineffective Government and Estates-General: By 1789, France’s financial situation had become so dire that Louis XVI called the Estates-General (a representative assembly) for the first time since 1614, to address the fiscal crisis. The Third Estate, feeling underrepresented and excluded from decision-making, eventually proclaimed itself the National Assembly and vowed to draft a new constitution, a move that challenged the authority of the king and sparked a political crisis.\n",
    "Economic Hardship and Unrest: With the economic difficulties and food shortages, bread prices soared, and many people could not afford basic food. This created widespread anger and unrest, particularly in urban areas. Many workers and artisans faced unemployment and poor living conditions, which further aggravated social tensions.\n",
    "''')\n",
    "'''\n",
    "Failure of Reform: Some attempts were made by the monarchy to implement reforms, such as calling the Estates-General or suggesting new tax policies, but these were either too little or too late. The reforms did not resolve the underlying economic and social issues, and the monarchy’s refusal to implement deeper changes contributed to the collapse of royal authority.\n",
    "The Influence of the American Revolution: The success of the American Revolution (1776) provided a model for challenging authority and achieving political change. The idea that a people could overthrow an oppressive government and establish a republic inspired many in France, particularly among the bourgeoisie and revolutionary thinkers.\n",
    "''';\n",
    "stud_ans = nlp(r'''Social Inequality: French society was divided into three estates. The First Estate consisted of the clergy, the Second Estate was made up of the nobility, and the Third Estate included peasants, city workers, and the bourgeoisie (middle class). The Third Estate made up about 98% of the population, but they were heavily taxed and had little political power, while the First and Second Estates enjoyed privileges. This created widespread frustration and resentment among the lower classes.\n",
    "Financial Crisis: By the late 1700s, France was in severe debt, primarily due to its involvement in expensive wars, like the American Revolution, and the lavish spending of King Louis XVI and his court. The government had to borrow large sums of money, leading to an economic crisis. The tax system was inefficient, and the burden fell on the common people, worsening their financial hardship.\n",
    "Enlightenment Ideas: The Enlightenment, a philosophical movement emphasizing reason, individual rights, and equality, influenced many French thinkers. Ideas about liberty, democracy, and the rights of man began to spread, encouraging people to question traditional authority and the monarchy. Thinkers like Rousseau, Voltaire, and Montesquieu inspired the desire for reform and change.\n",
    "Poor Harvests and Hunger: France suffered a series of bad harvests in the late 1780s, leading to food shortages, high bread prices, and widespread hunger. The harsh winters and poor agricultural conditions made life difficult for peasants and urban workers, which led to anger and unrest. The high price of bread, a staple food, was particularly damaging to the lower classes.\n",
    "Weak Leadership: King Louis XVI was seen as a weak and indecisive ruler. His inability to solve the financial crisis or address the grievances of the people made the monarchy appear ineffective. Queen Marie Antoinette was also unpopular, partly due to her lavish lifestyle, which contrasted sharply with the suffering of the common people.\n",
    "Estates-General and the National Assembly: In 1789, in an attempt to solve the financial crisis, Louis XVI called the Estates-General (a meeting of representatives from all three estates). The Third Estate, frustrated with their lack of power, broke away and declared themselves the National Assembly, signaling the start of a political revolution. They vowed to create a new constitution for France, leading to the formation of a revolutionary government.''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_ans = nlp(r'''French society was divided into three estates. The First Estate (clergy) and the Second Estate (nobility) enjoyed privileges, such as exemptions from taxes and special legal rights, while the Third Estate (commoners) paid most of the taxes and had little political power. The Third Estate, which made up about 98% of the population, included peasants, urban workers, and the bourgeoisie (middle class). The resentment of the inequalities between the estates contributed significantly to the revolutionary spirit.\n",
    "France was deeply in debt due to its involvement in expensive wars, particularly the American Revolution (1775–1783), and lavish spending by King Louis XVI and his court. The tax burden largely fell on the Third Estate, while the clergy and nobility were exempt. Efforts to reform the tax system were blocked by the privileged classes. Bad weather in the late 1780s caused crop failures, resulting in food shortages, high bread prices, and widespread hunger. This led to increased suffering for the common people.\n",
    "King Louis XVI was seen as an ineffective ruler who failed to address France’s financial problems. His indecisiveness and inability to implement necessary reforms weakened his authority. Queen Marie Antoinette, who was unpopular for her extravagant lifestyle and foreign origins, was often blamed for the financial crisis, further fueling discontent.\n",
    "The Enlightenment was an intellectual movement that emphasized reason, individual rights, and the idea of equality before the law. Philosophers like Jean-Jacques Rousseau, Voltaire, and Baron de Montesquieu criticized absolute monarchy and aristocratic privileges. These ideas inspired many in the Third Estate, especially the bourgeoisie, who sought greater political influence and reform of the outdated system.\n",
    "By 1789, France’s financial situation had become so dire that Louis XVI called the Estates-General (a representative assembly) for the first time since 1614, to address the fiscal crisis. The Third Estate, feeling underrepresented and excluded from decision-making, eventually proclaimed itself the National Assembly and vowed to draft a new constitution, a move that challenged the authority of the king and sparked a political crisis.\n",
    "With the economic difficulties and food shortages, bread prices soared, and many people could not afford basic food. This created widespread anger and unrest, particularly in urban areas. Many workers and artisans faced unemployment and poor living conditions, which further aggravated social tensions.\n",
    "''')\n",
    "'''\n",
    "Failure of Reform: Some attempts were made by the monarchy to implement reforms, such as calling the Estates-General or suggesting new tax policies, but these were either too little or too late. The reforms did not resolve the underlying economic and social issues, and the monarchy’s refusal to implement deeper changes contributed to the collapse of royal authority.\n",
    "The Influence of the American Revolution: The success of the American Revolution (1776) provided a model for challenging authority and achieving political change. The idea that a people could overthrow an oppressive government and establish a republic inspired many in France, particularly among the bourgeoisie and revolutionary thinkers.\n",
    "''';\n",
    "stud_ans = nlp(r'''French society was divided into three estates. The First Estate consisted of the clergy, the Second Estate was made up of the nobility, and the Third Estate included peasants, city workers, and the bourgeoisie (middle class). The Third Estate made up about 98% of the population, but they were heavily taxed and had little political power, while the First and Second Estates enjoyed privileges. This created widespread frustration and resentment among the lower classes.\n",
    "By the late 1700s, France was in severe debt, primarily due to its involvement in expensive wars, like the American Revolution, and the lavish spending of King Louis XVI and his court. The government had to borrow large sums of money, leading to an economic crisis. The tax system was inefficient, and the burden fell on the common people, worsening their financial hardship.\n",
    "The Enlightenment, a philosophical movement emphasizing reason, individual rights, and equality, influenced many French thinkers. Ideas about liberty, democracy, and the rights of man began to spread, encouraging people to question traditional authority and the monarchy. Thinkers like Rousseau, Voltaire, and Montesquieu inspired the desire for reform and change.\n",
    "France suffered a series of bad harvests in the late 1780s, leading to food shortages, high bread prices, and widespread hunger. The harsh winters and poor agricultural conditions made life difficult for peasants and urban workers, which led to anger and unrest. The high price of bread, a staple food, was particularly damaging to the lower classes.\n",
    "King Louis XVI was seen as a weak and indecisive ruler. His inability to solve the financial crisis or address the grievances of the people made the monarchy appear ineffective. Queen Marie Antoinette was also unpopular, partly due to her lavish lifestyle, which contrasted sharply with the suffering of the common people.\n",
    "In 1789, in an attempt to solve the financial crisis, Louis XVI called the Estates-General (a meeting of representatives from all three estates). The Third Estate, frustrated with their lack of power, broke away and declared themselves the National Assembly, signaling the start of a political revolution. They vowed to create a new constitution for France, leading to the formation of a revolutionary government.''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary:\n",
      "It is commonly used to summarize articles, documents, and other large texts. The goal is to retain key information while significantly reducing the text length. \n",
      "Text summarization is the process of distilling the most important information from a source text\n"
     ]
    }
   ],
   "source": [
    "# normal summarization\n",
    "\n",
    "from collections import Counter\n",
    "import math\n",
    "\n",
    "def text_summarization(text, max_threshold=0.05, min_threshold=0.01, summary_length=3):\n",
    "    # 1. Tokenize the text into words and split into sentences\n",
    "    sentences = text.split(\".\\n\")\n",
    "    words = text.split()\n",
    "    \n",
    "    # 2. Remove duplicates from the word list\n",
    "    unique_words = list(set(words))\n",
    "    \n",
    "    # 3. Count the frequency of each word\n",
    "    word_counts = Counter(words)\n",
    "    total_words = len(words)\n",
    "    \n",
    "    # 4. Calculate word percentage (frequency / total word count)\n",
    "    word_percentages = {word: freq / total_words for word, freq in word_counts.items()}\n",
    "    \n",
    "    # 5. Select average frequent words based on min and max thresholds\n",
    "    keywords = [word for word, percentage in word_percentages.items()\n",
    "                if min_threshold <= percentage <= max_threshold]\n",
    "    \n",
    "    # 6. Count window size and weight each sentence\n",
    "    sentence_weights = []\n",
    "    for sentence in sentences:\n",
    "        sentence_words = sentence.split()\n",
    "        significant_words = [word for word in sentence_words if word in keywords]\n",
    "        \n",
    "        if not significant_words:\n",
    "            continue\n",
    "        \n",
    "        # Window size: Maximum distance between keywords\n",
    "        positions = [sentence_words.index(word) for word in significant_words]\n",
    "        window_size = max(positions) - min(positions) + 1 if len(positions) > 1 else 1\n",
    "        \n",
    "        # Weight: (Number of keywords)^2 / window size\n",
    "        weight = (len(significant_words) ** 2) / window_size\n",
    "        sentence_weights.append((sentence, weight))\n",
    "    \n",
    "    # 7. Sort sentences by weight in descending order\n",
    "    sorted_sentences = sorted(sentence_weights, key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # 8. Select the top n sentences for the summary\n",
    "    summary_sentences = [sentence for sentence, weight in sorted_sentences[:summary_length]]\n",
    "    \n",
    "    return \". \".join(summary_sentences)\n",
    "\n",
    "# Example Usage\n",
    "text = \"\"\"\n",
    "Text summarization is the process of distilling the most important information from a source text.\n",
    "It is commonly used to summarize articles, documents, and other large texts.\n",
    "The goal is to retain key information while significantly reducing the text length.\n",
    "Automatic summarization techniques include extractive and abstractive methods.\n",
    "Extractive summarization selects sentences directly from the source text.\n",
    "Abstractive summarization generates new sentences that capture the essence of the original text.\n",
    "\"\"\"\n",
    "summary = text_summarization(text)\n",
    "print(\"Summary:\")\n",
    "print(summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary:\n",
      "It is commonly used to summarize articles, documents, and other large texts.\n",
      " \n",
      "Text summarization is the process of distilling the most important information from a source text.\n",
      " The goal is to retain key information while significantly reducing the text length.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# spacy summarization\n",
    "\n",
    "import spacy\n",
    "from collections import Counter\n",
    "import math\n",
    "\n",
    "def text_summarization_spacy(text, summary_length=3, max_threshold=0.05, min_threshold=0.01):\n",
    "    # Load the English NLP model from spaCy\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    doc = nlp(text)\n",
    "    \n",
    "    # 1. Tokenize the text into sentences and words\n",
    "    sentences = [sent.text for sent in doc.sents]\n",
    "    words = [token.text.lower() for token in doc if not token.is_punct and not token.is_space]\n",
    "    \n",
    "    # 2. Remove duplicates from the word list\n",
    "    unique_words = set(words)\n",
    "    \n",
    "    # 3. Count the frequency of each word\n",
    "    word_counts = Counter(words)\n",
    "    total_words = len(words)\n",
    "    \n",
    "    # 4. Calculate word percentage (frequency / total word count)\n",
    "    word_percentages = {word: freq / total_words for word, freq in word_counts.items()}\n",
    "    \n",
    "    # 5. Select average frequent words based on thresholds\n",
    "    keywords = [word for word, percentage in word_percentages.items()\n",
    "                if min_threshold <= percentage <= max_threshold]\n",
    "    \n",
    "    # 6. Count window size and weight each sentence\n",
    "    sentence_weights = []\n",
    "    for sentence in sentences:\n",
    "        sentence_doc = nlp(sentence)\n",
    "        sentence_words = [token.text.lower() for token in sentence_doc if not token.is_punct and not token.is_space]\n",
    "        significant_words = [word for word in sentence_words if word in keywords]\n",
    "        \n",
    "        if not significant_words:\n",
    "            continue\n",
    "        \n",
    "        # Window size: Maximum distance between keywords\n",
    "        positions = [sentence_words.index(word) for word in significant_words]\n",
    "        window_size = max(positions) - min(positions) + 1 if len(positions) > 1 else 1\n",
    "        \n",
    "        # Weight: (Number of keywords)^2 / window size\n",
    "        weight = (len(significant_words) ** 2) / window_size\n",
    "        sentence_weights.append((sentence, weight))\n",
    "    \n",
    "    # 7. Sort sentences by weight in descending order\n",
    "    sorted_sentences = sorted(sentence_weights, key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # 8. Select the top n sentences for the summary\n",
    "    summary_sentences = [sentence for sentence, weight in sorted_sentences[:summary_length]]\n",
    "    \n",
    "    return \" \".join(summary_sentences)\n",
    "\n",
    "# Example Usage\n",
    "text = \"\"\"\n",
    "Text summarization is the process of distilling the most important information from a source text.\n",
    "It is commonly used to summarize articles, documents, and other large texts.\n",
    "The goal is to retain key information while significantly reducing the text length.\n",
    "Automatic summarization techniques include extractive and abstractive methods.\n",
    "Extractive summarization selects sentences directly from the source text.\n",
    "Abstractive summarization generates new sentences that capture the essence of the original text.\n",
    "\"\"\"\n",
    "summary = text_summarization_spacy(text)\n",
    "print(\"Summary:\")\n",
    "print(summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Queen Marie Antoinette, who was unpopular for her extravagant lifestyle and foreign origins, was often blamed for the financial crisis, further fueling discontent.\\n Bad weather in the late 1780s caused crop failures, resulting in food shortages, high bread prices, and widespread hunger. France was deeply in debt due to its involvement in expensive wars, particularly the American Revolution (1775–1783), and lavish spending by King Louis XVI and his court. The tax burden largely fell on the Third Estate, while the clergy and nobility were exempt. The Third Estate, feeling underrepresented and excluded from decision-making, eventually proclaimed itself the National Assembly and vowed to draft a new constitution, a move that challenged the authority of the king and sparked a political crisis.\\n The Third Estate, which made up about 98% of the population, included peasants, urban workers, and the bourgeoisie (middle class).'"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_summarization_spacy(key_ans.text, 6)#, summarize(stud_ans.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The First Estate consisted of the clergy, the Second Estate was made up of the nobility, and the Third Estate included peasants, city workers, and the bourgeoisie (middle class). In 1789, in an attempt to solve the financial crisis, Louis XVI called the Estates-General (a meeting of representatives from all three estates). Ideas about liberty, democracy, and the rights of man began to spread, encouraging people to question traditional authority and the monarchy. They vowed to create a new constitution for France, leading to the formation of a revolutionary government. The government had to borrow large sums of money, leading to an economic crisis. The high price of bread, a staple food, was particularly damaging to the lower classes.\\n'"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_summarization_spacy(stud_ans.text, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1789 , attempt solve financial crisis , louis xvi estates - general ( meeting representative estate ) . king louis xvi weak indecisive ruler . vow create new constitution france , lead formation revolutionary government . inability solve financial crisis address grievance people monarchy appear ineffective . government borrow large sum money , lead economic crisis . tax system inefficient , burden fall common people , worsen financial hardship .'"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_summarization_spacy(remove_stopwords(lemmatize_text(stud_ans.text)), 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "785479758fb44f80a749dd89cfddf46f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/229 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\adity\\anaconda3\\envs\\myenv\\lib\\site-packages\\huggingface_hub\\file_download.py:159: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\adity\\.cache\\huggingface\\hub\\models--sentence-transformers--paraphrase-MiniLM-L6-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82e542afc4854dd1a16abb840d3d08da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/122 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5b384e5c3bb4a44a8df7f609800171e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/3.73k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76c8634492054ec7a370938c72657e39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05405c740c994ea5be5c13a7fdc02d42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/629 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de472057f6f74831848d422a267de314",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b877ea8f3304fac9e3638594271f8e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/314 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f2809dcec6e4c3aae4b9e7900be0344",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63481bcbb3ed4a6eb4d0b0be5dedc7cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "361a370d85d2450ab571e8cdf8150cd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13a9434af8e847a7b582f73b19b96427",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer('sentence-transformers/paraphrase-MiniLM-L6-v2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dab4f8e25228489fb0bace25d4f72a58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0f324f256364903bb87a6895430d0d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.88476187\n"
     ]
    }
   ],
   "source": [
    "t1 = '''Beneath the canopy of an ancient forest, sunlight filtered through the dense lattice of leaves, casting dappled patterns on the moss-covered ground. The air was thick with the earthy aroma of damp soil and the occasional sweet scent of blooming wildflowers. Birds chirped melodiously, their songs harmonizing with the gentle rustle of leaves stirred by a faint breeze. Hidden among the underbrush, a small fox observed the scene with curious eyes, its fur blending seamlessly with the auburn hues of fallen leaves. The forest seemed alive, a timeless sanctuary where every whisper of the wind told stories of resilience and renewal.\n",
    "'''\n",
    "t2 = '''In the bustling heart of the city, life moved at a relentless pace. Cars honked impatiently, weaving through crowded streets lined with towering skyscrapers that glinted in the morning sun. Vendors shouted to attract passersby, their stalls overflowing with fresh produce, vibrant textiles, and an assortment of trinkets. Amid the chaos, a street performer played a soulful tune on his violin, momentarily drawing a small crowd. The melody, rich with emotion, offered a brief reprieve from the cacophony, reminding everyone of the beauty hidden in the everyday hustle. Above, the sky was a patchwork of clouds and smog, a testament to the city's ceaseless activity.'''\n",
    "\n",
    "embeddings1 = model.encode(key_ans.text)\n",
    "embeddings2 = model.encode(stud_ans.text)\n",
    "print(cosine_similarity([embeddings1], [embeddings2])[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_sentences(sentences, n):\n",
    "    m = len(sentences)\n",
    "    if m <= n:\n",
    "        # If fewer sentences than clusters, each sentence is a cluster\n",
    "        return [[sentence] for sentence in sentences]\n",
    "\n",
    "    # Calculate similarities between consecutive sentences\n",
    "    similarities = [avg_similarity(sentences[i], sentences[i + 1]) for i in range(m - 1)]\n",
    "\n",
    "    # Find indices of the (m - n) smallest similarities\n",
    "    partition_indices = sorted(range(len(similarities)), key=lambda i: similarities[i])[:n - 1]\n",
    "\n",
    "    # Sort partition indices to split sentences sequentially\n",
    "    partition_indices.sort()\n",
    "\n",
    "    # Partition sentences based on the identified indices\n",
    "    clusters = []\n",
    "    prev_index = 0\n",
    "    for idx in partition_indices:\n",
    "        clusters.append(sentences[prev_index:idx + 1])\n",
    "        prev_index = idx + 1\n",
    "    clusters.append(sentences[prev_index:])  # Add the final cluster\n",
    "\n",
    "    return clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['a'], ['b'], ['c'], ['d'], ['e']]\n"
     ]
    }
   ],
   "source": [
    "sentences = [\"a\", \"b\", \"c\", \"d\", \"e\"]\n",
    "n = 7\n",
    "clusters = cluster_sentences(sentences, n)\n",
    "print(clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_answers(student_answer, answer_key, max_marks):\n",
    "    \n",
    "    # student_answer = nlp(preprocess_text(student_answer))\n",
    "    # answer_key = nlp(preprocess_text(answer_key))\n",
    "    \n",
    "    # Get the sentences from the student answer and the answer key\n",
    "    student_sentences = [str(i) for i in student_answer.sents]\n",
    "    answer_key_sentences = [str(i) for i in answer_key.sents]\n",
    "    \n",
    "    student_clusters = cluster_sentences(student_sentences, max_marks)\n",
    "    key_clusters = cluster_sentences(answer_key_sentences, max_marks)\n",
    "    for i in student_clusters:\n",
    "        print(i)\n",
    "    for i in key_clusters:\n",
    "        print(i)\n",
    "    \n",
    "    total_marks = 0\n",
    "\n",
    "    # Compare student clusters with key clusters\n",
    "    for student_cluster in student_clusters:\n",
    "        similarity_dict = {}\n",
    "        \n",
    "        for student_sentence in student_cluster:\n",
    "            # Compare each student sentence with each sentence in the answer key\n",
    "            for key_cluster in key_clusters:\n",
    "                for key_sentence in key_cluster:\n",
    "                    similarity = avg_similarity(student_sentence, key_sentence)\n",
    "                    similarity_dict[key_sentence] = similarity\n",
    "        \n",
    "        # Find the key sentence with the maximum similarity\n",
    "        max_pair = max(similarity_dict, key=similarity_dict.get)\n",
    "        max_key_sentence = max_pair\n",
    "        \n",
    "        # Find the cluster associated with the key sentence\n",
    "        key_cluster = next(cluster for cluster in key_clusters if max_key_sentence in cluster)\n",
    "        \n",
    "        # Calculate the average similarity between clusters\n",
    "        cluster_similarities = []\n",
    "        for student_sentence in student_cluster:\n",
    "            for key_sentence in key_cluster:\n",
    "                cluster_similarities.append(avg_similarity(student_sentence, key_sentence))\n",
    "        \n",
    "        average_similarity = sum(cluster_similarities) / len(cluster_similarities)\n",
    "        \n",
    "        # Add 1 mark if average similarity > 0.5\n",
    "        print(average_similarity)\n",
    "        if average_similarity > 0.3:\n",
    "            total_marks += 1\n",
    "        \n",
    "        # Remove the used key cluster\n",
    "        key_clusters.remove(key_cluster)\n",
    "    \n",
    "    return total_marks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "a1 = nlp(r'''\n",
    "Cardiac muscles contract automatically and rhythmically, controlled by the autonomic nervous system and specialized pacemaker cells. Intercalated Discs are unique junctions between cardiac muscle cells that contain gap junctions and desmosomes. They allow for synchronized contraction by enabling rapid electrical signal transmission and maintaining structural integrity during powerful contractions. Cardiac muscles have a striated structure similar to skeletal muscles, with alternating light and dark bands, due to the arrangement of actin and myosin filaments.\n",
    "''')\n",
    "a2 = nlp(r'''Cardiac muscles work automatically without conscious control, helping the heart pump blood continuously. They have a striated (striped) appearance due to the arrangement of actin and myosin filaments, similar to skeletal muscles. Cardiac muscles are interconnected by intercalated discs, which allow rapid transmission of electrical signals, ensuring synchronized contraction of the heart.\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\nCardiac muscles contract automatically and rhythmically, controlled by the autonomic nervous system and specialized pacemaker cells.', 'Intercalated Discs are unique junctions between cardiac muscle cells that contain gap junctions and desmosomes.']\n",
      "['They allow for synchronized contraction by enabling rapid electrical signal transmission and maintaining structural integrity during powerful contractions.']\n",
      "['Cardiac muscles have a striated structure similar to skeletal muscles, with alternating light and dark bands, due to the arrangement of actin and myosin filaments.\\n']\n",
      "['Cardiac muscles work automatically without conscious control, helping the heart pump blood continuously.']\n",
      "['They have a striated (striped) appearance due to the arrangement of actin and myosin filaments, similar to skeletal muscles.']\n",
      "['Cardiac muscles are interconnected by intercalated discs, which allow rapid transmission of electrical signals, ensuring synchronized contraction of the heart.\\n']\n",
      "0.5305729537022437\n",
      "0.19497125148773192\n",
      "0.7177497672828246\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare_answers(a1, a2, 3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
